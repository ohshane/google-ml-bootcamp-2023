{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seq2Seq\n",
    "\n",
    "<img src=\"https://wikidocs.net/images/page/24996/인코더디코더모델.PNG\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Teacher forcing\n",
    "\n",
    "We can use ground truth as a decoder's input for parallelization. Otherwise the output value of a decoder is used as the next input by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([28, 128, 100])"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "\n",
    "input_dim = 100\n",
    "hidden_dim = 200\n",
    "output_dim = 100\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, batch_first=False):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.batch_first = batch_first\n",
    "\n",
    "        self.rnn = nn.GRU(input_dim, hidden_dim, batch_first=batch_first)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        _, hx = self.rnn(x)\n",
    "        return hx\n",
    "\n",
    "class Decoder(nn.Module): # actually a generator\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, batch_first=False):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.batch_first = batch_first\n",
    "    \n",
    "        self.rnn = nn.GRU(input_dim, hidden_dim, batch_first=batch_first)\n",
    "        self.linear = nn.Linear(hidden_dim, output_dim)\n",
    "    \n",
    "    def forward(self, x, hx):\n",
    "        x, hx = self.rnn(x, hx)\n",
    "        output = self.linear(hx)\n",
    "        return output, x, hx\n",
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, batch_first=False):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "    \n",
    "    def forward(self, source, target, teacher_forcing_ratio=0.8):\n",
    "        x = target[0].unsqueeze(0)\n",
    "        hx = self.encoder(source)\n",
    "\n",
    "        predicts = []\n",
    "        for i in range(len(target)):\n",
    "            output, x, hx = self.decoder(x, hx)\n",
    "            predicts.append(output)\n",
    "\n",
    "            if random.random() < teacher_forcing_ratio:\n",
    "                x = target[i].unsqueeze(0)\n",
    "            else:\n",
    "                x = output\n",
    "        predicts = torch.concat(predicts, dim=0)\n",
    "        return predicts\n",
    "\n",
    "\n",
    "encoder = Encoder(input_dim=100, hidden_dim=200)\n",
    "decoder = Decoder(input_dim=100, hidden_dim=200, output_dim=100)\n",
    "\n",
    "seq2seq = Seq2Seq(encoder, decoder)\n",
    "\n",
    "source = torch.randn(56, 128, 100)\n",
    "target = torch.randn(28, 128, 100)\n",
    "\n",
    "seq2seq(source, target).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Beam search\n",
    "\n",
    "$$\n",
    "\\argmax_{y} \\prod_{t=1}^{T_y} p(y^{<t>} | x, y^{<1>}, \\cdots, y^{<t-1>}) \\\\\n",
    "\n",
    "\\argmax_{y} \\frac{1}{T_y^{\\alpha}} \\sum_{t=1}^{T_y} \\log p(y^{<t>} | x, y^{<1>}, \\cdots, y^{<t-1>}) \\quad \\text{where,}\\ 0 \\leq \\alpha \\leq 1\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b =  1 ('YASANOGDGDHQFPETDNRU', -1.798972939125831)\n",
      "b =  2 ('YASACGAWCMNQGNZOVDTS', -1.6200365243245871)\n",
      "b =  3 ('YASACGABGCHKPRBIELIR', -1.630091767739598)\n",
      "b =  4 ('YASACGAWCMNCNAODDOIA', -1.5992422080213697)\n",
      "b =  5 ('YASACGAWCMNCNAODDOIA', -1.5992422080213697)\n",
      "b =  6 ('YASACGAWCMNCNAODDOIA', -1.5992422080213697)\n",
      "b =  7 ('YASACGAWCMNCNAODDOIA', -1.5992422080213697)\n",
      "b =  8 ('YASACGAWCMNCNAODDOIA', -1.5992422080213697)\n",
      "b =  9 ('YASACGAWCMNCNAODDOIA', -1.5992422080213697)\n",
      "b = 10 ('YASACGAWCMNCNAODDOIA', -1.5992422080213697)\n",
      "b = 11 ('YASACGAWCMNCNAODDOIA', -1.5992422080213697)\n",
      "b = 12 ('YASACGAWCMNCNAODDOIA', -1.5992422080213697)\n",
      "b = 13 ('YASACGAWCMNCNAODDOIA', -1.5992422080213697)\n",
      "b = 14 ('YASACGAWCMNCNAODDOIA', -1.5992422080213697)\n",
      "b = 15 ('YASACGAWCMNCNAODDOIA', -1.5992422080213697)\n",
      "b = 16 ('YASACGAWCMNCNAODDOIA', -1.5992422080213697)\n",
      "b = 17 ('YASACGAWCMNCNAODDOIA', -1.5992422080213697)\n",
      "b = 18 ('YASACGAWCMNCNAODDOIA', -1.5992422080213697)\n",
      "b = 19 ('YASACGAWCMNCNAODDOIA', -1.5992422080213697)\n",
      "b = 20 ('YASACGAWCMNCNAODDOIA', -1.5992422080213697)\n",
      "b = 21 ('YJPRAVKWOBHCJPMIANQG', -1.592609660939457)\n",
      "b = 22 ('YJPRAVKWOBHCJPMIANQG', -1.592609660939457)\n",
      "b = 23 ('YASACCWSLAWNOHPWOZLL', -1.5921603150233121)\n",
      "b = 24 ('YASACCWSLAWNOHPWOZLL', -1.5921603150233121)\n",
      "b = 25 ('YASACCWSLAWNOHPWOZLL', -1.5921603150233121)\n",
      "b = 26 ('YASACCWSLAWNOHPWOZLL', -1.5921603150233121)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "chars = list(map(chr, range(65,91)))\n",
    "\n",
    "def model(x: str) -> np.array:\n",
    "    np.random.seed(hash(x) % 10**9)\n",
    "    x = np.random.randn(len(chars))\n",
    "    x = np.exp(x) / np.exp(x).sum()\n",
    "    np.random.seed()\n",
    "    return x # random softmax (proba) from the input x\n",
    "\n",
    "# imagine something like a genetic algorithm selecting the top-k for each iterations\n",
    "def beam(breadth=3, depth=10, log=True, alpha=1):\n",
    "    choices = [(\"\", np.log(1.0))] if log else [(\"\", 1.0)]\n",
    "    for d in range(depth):\n",
    "        candidates = []\n",
    "        for seq, proba in choices:\n",
    "            preds = model(seq)\n",
    "            if log:\n",
    "                candidates.extend(zip([seq+c for c in chars], proba+np.log(preds)))\n",
    "            else:\n",
    "                candidates.extend(zip([seq+c for c in chars], proba*preds))\n",
    "        candidates = sorted(candidates, key=lambda x: x[1], reverse=True)\n",
    "        choices = candidates[:breadth]\n",
    "    if log:\n",
    "        choices = [(seq, 1/depth**alpha * proba) for seq, proba in choices]\n",
    "    return choices\n",
    "\n",
    "# for b in range(1, len(chars)+1):\n",
    "#     print(f\"{b = :>2}\", beam(breadth=b, depth=20, log=False)[0])\n",
    "\n",
    "for b in range(1, len(chars)+1):\n",
    "    print(f\"{b = :>2}\", beam(breadth=b, depth=20, log=True)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Error analysis on beam search\n",
    "\n",
    "Human ($y^*$): \"Jane visits Africa in September.\" \\\n",
    "Model ($\\hat y$): \"Jane visited Africa last September.\"\n",
    "\n",
    "$$\n",
    "\\begin{cases}\n",
    "p(y^*|x) > p(\\hat y|x) \\rightarrow \\text{beam search is at fault} \\\\\n",
    "p(y^*|x) \\leq p(\\hat y|x) \\rightarrow \\text{model is at fault} \\\\\n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bleu Score\n",
    "Bleu stands for Bilingual evaluation understudy\n",
    "\n",
    "Bleu score is a \"precision\" of a generated sequence.\n",
    "\n",
    "<img src=\"https://images.prismic.io/encord/edfa849b-03fb-43d2-aba5-1f53a8884e6f_image5.png\" height=300 />\n",
    "\n",
    "<img src=\"https://dp8v87cz8a7qa.cloudfront.net/45396/5bd20d03240611540492547.png\" height=200 />\n",
    "\n",
    "```\n",
    "  ┌─GroundTruth────────────┐ \n",
    "  │                        │ \n",
    "  │                        │ \n",
    "  │                        │ \n",
    "  │┌─MachineTranslation────┼┐\n",
    "  ││                       ││\n",
    "  ││ Bleu (Precision)      ││\n",
    "  │└───────────────────────┼┘\n",
    "  └────────────────────────┘ \n",
    "```\n",
    "Better not to generate creative words.\n",
    "\n",
    "<img src=\"src/bleu_details.png\" height=200 />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reference_words  = {'a': 1, 'on': 1, 'mat': 1, 'is': 1, 'cat': 1, 'the': 1, 'there': 1}\n",
      "translated_words = {'a': 4, 'cute': 1, 'cat': 1, 'is': 1, 'lying': 1, 'on': 1, 'cozy': 1, 'mat': 1}\n",
      "bleu = 0.45454545454545453\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import pandas as pd\n",
    "\n",
    "references = [\n",
    "    \"the cat is on the mat\",\n",
    "    \"there is a cat on the mat\",\n",
    "]\n",
    "\n",
    "translation = \"a cute cat is lying on a cozy mat\"\n",
    "\n",
    "reference_words = []\n",
    "for sentence in references:\n",
    "    reference_words.extend(sentence.split())\n",
    "reference_words = dict.fromkeys(set(reference_words), 1)\n",
    "\n",
    "translated_words = translation.split()\n",
    "translated_words = dict(Counter(translated_words))\n",
    "\n",
    "print(f\"{reference_words  = }\")\n",
    "print(f\"{translated_words = }\")\n",
    "\n",
    "TP = 0\n",
    "P  = 0\n",
    "for k in translated_words:\n",
    "    if k in reference_words:\n",
    "        TP += reference_words[k]\n",
    "    P += translated_words[k]\n",
    "\n",
    "bleu = TP / P\n",
    "print(f\"{bleu = }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attention mechanism\n",
    "\n",
    "Simply calculate the attention value of $\\mathbf a^{<t'>}$; an output value of bidirectional RNN at sequence $\\mathbf x^{<t'>}$.\n",
    "\n",
    "$$\n",
    "\\mathbf{a}^{<t'>} =\n",
    "\\begin{bmatrix}\n",
    "\\vert \\\\\n",
    "\\mathbf{a}_{\\text{forward}}^{<t'>}\\\\\n",
    "\\vert \\\\\n",
    "\\hline\n",
    "\\vert \\\\\n",
    "\\mathbf{a}_{\\text{backward}}^{<t'>}\\\\\n",
    "\\vert \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$$\n",
    "e^{<t,t'>} = \n",
    "W\n",
    "\\begin{bmatrix}\n",
    "\\vert \\\\\n",
    "\\mathbf{a}^{<t'>}\\\\\n",
    "\\vert \\\\\n",
    "\\hline\n",
    "\\vert \\\\\n",
    "\\mathbf{s}^{<t'-1>}\\\\\n",
    "\\vert \\\\\n",
    "\\end{bmatrix}\n",
    "+ b\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\mathbf e^{<t>} = \n",
    "\\begin{bmatrix}\n",
    "e^{<t,1>} \\\\\n",
    "e^{<t,2>} \\\\\n",
    "\\vdots \\\\\n",
    "e^{<t,t'>} \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\mathrm{softmax}(\\mathbf e^{<t>}) =\n",
    "\\begin{bmatrix}\n",
    "\\alpha^{<t,1>} \\\\\n",
    "\\alpha^{<t,2>} \\\\\n",
    "\\vdots \\\\\n",
    "\\alpha^{<t,t'>} \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\mathbf c^{<t>}=\n",
    "\n",
    "\\begin{bmatrix}\n",
    "\\vert  & \\vert & & \\vert \\\\\n",
    "\\mathbf{a}^{<1>} & \\mathbf{a}^{<2>} & \\cdots & \\mathbf{a}^{<t'>} \\\\\n",
    "\\vert  & \\vert & & \\vert \\\\\n",
    "\\end{bmatrix}\n",
    "\n",
    "\\begin{bmatrix}\n",
    "\\alpha^{<t,1>} \\\\\n",
    "\\alpha^{<t,2>} \\\\\n",
    "\\vdots \\\\\n",
    "\\alpha^{<t,t'>} \\\\\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div><img src=\"src/attention.png\" width=800 /></div>\n",
    "<div><img src=\"src/attention_e.png\" width=800 /></div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a.shape = torch.Size([56, 128, 400])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([28, 128, 200])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# attention model input size of 56, output size of 28\n",
    "# BiRNN length of 56, RNN length of 28\n",
    "\n",
    "birnn = nn.RNN(input_size=100, hidden_size=200, bidirectional=True)\n",
    "rnn   = nn.RNN(input_size=400, hidden_size=200, bidirectional=False)\n",
    "attention = nn.Linear(600, 1)\n",
    "\n",
    "x = torch.randn(56,128,100)\n",
    "a, _ = birnn(x) # activated value 'a' from birnn\n",
    "\n",
    "print(f\"{a.shape = }\")\n",
    "\n",
    "s = torch.zeros(1,128,200) # rnn's initial hidden state\n",
    "outputs = []\n",
    "for t in range(28):\n",
    "    e = attention(torch.concat([s.repeat(56,1,1), a], dim=2))\n",
    "    alpha = F.softmax(e, dim=0)\n",
    "    c = (a * alpha).sum(0, keepdim=True)\n",
    "    output, s = rnn(c, s)\n",
    "    outputs.append(output)\n",
    "\n",
    "outputs = torch.concat(outputs, dim=0)\n",
    "outputs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CTC cost for speech recognition\n",
    "\n",
    "On a typical STT recognition, we use a many-to-many architectrue which takes an audio sampled with 120hz as an input and a softmaxed text as an output.\n",
    "\n",
    "When speech of 30 seconds recorded with 120hz, the input and output sequence length will be 3600. Which will make the output sequence very sparse.\n",
    "\n",
    "To overcome this problem we keep the output sequence length to 3600 and use the CTC (connectionist temporal classification).\n",
    "\n",
    "Identical repeated chars not sparated by the blank (\"_\") are collapsed.\n",
    "\n",
    "The following string will collapse to \"the qui\".\n",
    "\n",
    "```\n",
    " _  t  t  _  h  h  h  _  e  _       q   _   u   u   _   i   i   i\n",
    "<1><2><3><4><5><6><7><8><9><10><11><12><13><14><15><16><17><18><19>\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trigger word detection\n",
    "\n",
    "We could put single 1 as an output to the starting point of the trigger word audio but the output will be very sparse.\\\n",
    "Instead, we can put some trailing 1s after the starting point to balance the sparsity.\n",
    "\n",
    "<div><img src=\"src/triggerword_basic.png\" width=600 /></div>\n",
    "<div><img src=\"src/triggerword_hack.png\" width=600 /></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
