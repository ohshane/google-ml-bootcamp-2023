{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seq2Seq\n",
    "\n",
    "<img src=\"https://wikidocs.net/images/page/24996/인코더디코더모델.PNG\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Teacher forcing\n",
    "\n",
    "We can use ground truth as a decoder's input for parallelization. Otherwise the output value of a decoder is used as the next input by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([28, 128, 100])"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "\n",
    "input_dim = 100\n",
    "hidden_dim = 200\n",
    "output_dim = 100\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, batch_first=False):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.batch_first = batch_first\n",
    "\n",
    "        self.rnn = nn.GRU(input_dim, hidden_dim, batch_first=batch_first)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        _, hx = self.rnn(x)\n",
    "        return hx\n",
    "\n",
    "class Decoder(nn.Module): # actually a generator\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, batch_first=False):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.batch_first = batch_first\n",
    "    \n",
    "        self.rnn = nn.GRU(input_dim, hidden_dim, batch_first=batch_first)\n",
    "        self.linear = nn.Linear(hidden_dim, output_dim)\n",
    "    \n",
    "    def forward(self, x, hx):\n",
    "        x, hx = self.rnn(x, hx)\n",
    "        output = self.linear(hx)\n",
    "        return output, x, hx\n",
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, batch_first=False):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "    \n",
    "    def forward(self, source, target, teacher_forcing_ratio=0.8):\n",
    "        x = target[0].unsqueeze(0)\n",
    "        hx = self.encoder(source)\n",
    "\n",
    "        predicts = []\n",
    "        for i in range(len(target)):\n",
    "            output, x, hx = self.decoder(x, hx)\n",
    "            predicts.append(output)\n",
    "\n",
    "            if random.random() < teacher_forcing_ratio:\n",
    "                x = target[i].unsqueeze(0)\n",
    "            else:\n",
    "                x = output\n",
    "        predicts = torch.concat(predicts, dim=0)\n",
    "        return predicts\n",
    "\n",
    "\n",
    "encoder = Encoder(input_dim=100, hidden_dim=200)\n",
    "decoder = Decoder(input_dim=100, hidden_dim=200, output_dim=100)\n",
    "\n",
    "seq2seq = Seq2Seq(encoder, decoder)\n",
    "\n",
    "source = torch.randn(56, 128, 100)\n",
    "target = torch.randn(28, 128, 100)\n",
    "\n",
    "seq2seq(source, target).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Beam search\n",
    "\n",
    "$$\n",
    "\\argmax_{y} \\prod_{t=1}^{T_y} p(y^{<t>} | x, y^{<1>}, \\cdots, y^{<t-1>}) \\\\\n",
    "\n",
    "\\argmax_{y} \\frac{1}{T_y^{\\alpha}} \\sum_{t=1}^{T_y} \\log p(y^{<t>} | x, y^{<1>}, \\cdots, y^{<t-1>}) \\quad \\text{where,}\\ 0 \\leq \\alpha \\leq 1\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b =  1 ('YASANOGDGDHQFPETDNRU', -1.798972939125831)\n",
      "b =  2 ('YASACGAWCMNQGNZOVDTS', -1.6200365243245871)\n",
      "b =  3 ('YASACGABGCHKPRBIELIR', -1.630091767739598)\n",
      "b =  4 ('YASACGAWCMNCNAODDOIA', -1.5992422080213697)\n",
      "b =  5 ('YASACGAWCMNCNAODDOIA', -1.5992422080213697)\n",
      "b =  6 ('YASACGAWCMNCNAODDOIA', -1.5992422080213697)\n",
      "b =  7 ('YASACGAWCMNCNAODDOIA', -1.5992422080213697)\n",
      "b =  8 ('YASACGAWCMNCNAODDOIA', -1.5992422080213697)\n",
      "b =  9 ('YASACGAWCMNCNAODDOIA', -1.5992422080213697)\n",
      "b = 10 ('YASACGAWCMNCNAODDOIA', -1.5992422080213697)\n",
      "b = 11 ('YASACGAWCMNCNAODDOIA', -1.5992422080213697)\n",
      "b = 12 ('YASACGAWCMNCNAODDOIA', -1.5992422080213697)\n",
      "b = 13 ('YASACGAWCMNCNAODDOIA', -1.5992422080213697)\n",
      "b = 14 ('YASACGAWCMNCNAODDOIA', -1.5992422080213697)\n",
      "b = 15 ('YASACGAWCMNCNAODDOIA', -1.5992422080213697)\n",
      "b = 16 ('YASACGAWCMNCNAODDOIA', -1.5992422080213697)\n",
      "b = 17 ('YASACGAWCMNCNAODDOIA', -1.5992422080213697)\n",
      "b = 18 ('YASACGAWCMNCNAODDOIA', -1.5992422080213697)\n",
      "b = 19 ('YASACGAWCMNCNAODDOIA', -1.5992422080213697)\n",
      "b = 20 ('YASACGAWCMNCNAODDOIA', -1.5992422080213697)\n",
      "b = 21 ('YJPRAVKWOBHCJPMIANQG', -1.592609660939457)\n",
      "b = 22 ('YJPRAVKWOBHCJPMIANQG', -1.592609660939457)\n",
      "b = 23 ('YASACCWSLAWNOHPWOZLL', -1.5921603150233121)\n",
      "b = 24 ('YASACCWSLAWNOHPWOZLL', -1.5921603150233121)\n",
      "b = 25 ('YASACCWSLAWNOHPWOZLL', -1.5921603150233121)\n",
      "b = 26 ('YASACCWSLAWNOHPWOZLL', -1.5921603150233121)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "chars = list(map(chr, range(65,91)))\n",
    "\n",
    "def model(x: str) -> np.array:\n",
    "    np.random.seed(hash(x) % 10**9)\n",
    "    x = np.random.randn(len(chars))\n",
    "    x = np.exp(x) / np.exp(x).sum()\n",
    "    np.random.seed()\n",
    "    return x # random softmax (proba) from the input x\n",
    "\n",
    "# imagine something like a genetic algorithm selecting the top-k for each iterations\n",
    "def beam(breadth=3, depth=10, log=True, alpha=1):\n",
    "    choices = [(\"\", np.log(1.0))] if log else [(\"\", 1.0)]\n",
    "    for d in range(depth):\n",
    "        candidates = []\n",
    "        for seq, proba in choices:\n",
    "            preds = model(seq)\n",
    "            if log:\n",
    "                candidates.extend(zip([seq+c for c in chars], proba+np.log(preds)))\n",
    "            else:\n",
    "                candidates.extend(zip([seq+c for c in chars], proba*preds))\n",
    "        candidates = sorted(candidates, key=lambda x: x[1], reverse=True)\n",
    "        choices = candidates[:breadth]\n",
    "    if log:\n",
    "        choices = [(seq, 1/depth**alpha * proba) for seq, proba in choices]\n",
    "    return choices\n",
    "\n",
    "# for b in range(1, len(chars)+1):\n",
    "#     print(f\"{b = :>2}\", beam(breadth=b, depth=20, log=False)[0])\n",
    "\n",
    "for b in range(1, len(chars)+1):\n",
    "    print(f\"{b = :>2}\", beam(breadth=b, depth=20, log=True)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Error analysis on beam search\n",
    "\n",
    "Human ($y^*$): \"Jane visits Africa in September.\" \\\n",
    "Model ($\\hat y$): \"Jane visited Africa last September.\"\n",
    "\n",
    "$$\n",
    "\\begin{cases}\n",
    "p(y^*|x) > p(\\hat y|x) \\rightarrow \\text{beam search is at fault} \\\\\n",
    "p(y^*|x) \\leq p(\\hat y|x) \\rightarrow \\text{model is at fault} \\\\\n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
